<html>
  <br></br><br></br>
  <body>
    <font size="+1"><h3 style="text-align: center;">METHOD</h3>
    <h2 style="text-align: center;">&nbsp;<strong>Simulate concept learning with neurocomputational models</strong></h2>
    <br>
    
    <p style="text-align: justify; font-size: 18px; padding: 0px 00 40px 0px;margin-left:20%; margin-right:20%">The current work applied neurocomputation to evaluate neuronal differences in the conceptual representations of objects when they were paired with proper names and category labels. The goal was to unfold the differential neural and cognitive basis of proper names and category labels during semantic learning and concept formation. Additionally, the current work assessed the generalization performance of this deep neural network model by comparing the extent to which novel instances could activate the neural network in the same manner as the training instances of their category did. We used the brain-constrained deep neural network model with spiking neurons and twelve areas in the left-hemispheric language-dominant fronto-temporo-occipital regions described in previous studies by <a href="https://www.frontiersin.org/article/10.3389/fncom.2018.00088" style="font-style: italic; color: black">Tomasello et al. (2018)</a> and <a href="https://doi.org/10.1007/s00426-021-01591-6" style="font-style: italic; color: black">Henningsen-Schomers & Pulvermüller (2021)</a>.</p>

    
    
    <h3 style="text-align: center;">&nbsp;<strong>Neuroanatomically and neurophysiologically inspired network models</strong></h3>
    <p style="text-align: left;">The architecture modelled three areas representing the ventral visual system (i.e., primary visual cortex <i>*V1</i>, temporo-occipital area <i>*TO</i>, anterior-temporal area <i>*AT</i>) and three areas representing the dorsolateral action system (i.e. , dorsolateral fronto-central motor <i>*M1L</i>, premotor cortex <i>*PML</i>, prefrontal cortex <i>*PFL</i>). These formed the extrasylvian region for sensorimotor processing where semantic information was stored. Another 6 areas of the perisylvian region for word-form processing which housed articulatory-phonological and acoustic-phonological information. These areas involved the three auditory areas (i.e., primary auditory cortex <i>*A1</i>, auditory belt <i>*AB</i>, parabelt areas <i>*PB</i>) and three articulatory areas (i.e., inferior primary motor cortex <i>*M1i</i>, inferior premotor cortex <i>*PMi</i>, multimodal prefrontal motor cortex <i>*PFi</i>), respectively. Between-area connections were established in a way that prefer adjacent neighbors although linkages to next-neighbor areas were also available. In this structure, long-distance corticocortical links were replicated according to neuroanatomical evidence in the literature.</p>
    <p class="aligncenter" style="padding: 10px 0em 10px 0;"><img src="426_2021_1591_Fig2_HTML.png" width="800" alt="centered image"></p>
    <p style="text-align: center;"><strong>Figure 1.</strong> Anatomical and connectivity architecture of the deep neural network model. Image taken from <a href="https://link.springer.com/article/10.1007/s00426-021-01591-6/Figures/2" style="font-style: italic; color: black">Henningsen-Schomers & Pulvermüller (2021)</a>.</p>
    <br></br>
    
    
    
    
    
    <h3 style="text-align: center;">&nbsp;<strong>The paradigm</strong></h3>
    <h4 style="text-align: left;; padding: 10px 00 5px 0px;">&nbsp;<strong>Design</strong></h4>
    <p style="text-align: left;">Training was conducted with 30 training instances, each thought to represent one specific object, belonging to 10 semantic categories (i.e., each category was grounded in 3 instances) (Figure 2A). Each instance was neuronally coded as a set of perceptual neuron activations (conceptual grounding pattern), which could be paired with a second pattern of neuronal activation in articulatory and auditory cortex, thought to implement verbal labels (wordform grounding pattern). These labels were either proper names and therefore specific to one grounding pattern, or category label and therefore the same symbol pattern co-occurred with all three grounding patterns of one category. To control for the effect of non-linguistic factors, a third class of training instances was learnt without concordant auditory-articulatory activation. This configuration yielded three training conditions: Proper Name, Category Label, and No Label, respectively. Learning performance was assessed on the 30 former and 30 novel instances in the test phase. These test instances were presented without the presence of any label, regardless of labeling conditions (Figure 2B). </p>
    <p class="aligncenter" style="padding: 0px 0em 10px 0;"><img src="Design.png" width="800" alt="centered image"></p>
    <p style="text-align: center;"><strong>Figure 2.</strong> <strong>(A)</strong> TRAINING: The neural network model was trained on 10 categories, each containing 3 training instances. The training instances of the same category were labelled either by the same category label or by their distinct proper names. <strong>(B)</strong> TEST: For each of the 10 categories we presented to the neural network 3 training instances together with 3 novel instances.</p>
    
    
    <h4 style="text-align: left; padding: 10px 00 5px 0px;">&nbsp;<strong>Grounding patterns</strong></h4>
    <p style="text-align: left;">Sensorimotor experiences induced by the instances and auditory-articulatory inputs (labels) were represented by conceptual and wordform grounding patterns, respectively. We generated three classes of patterns:</p>
    <ol type="i">
      <li style="text-align: left;margin-left:10%;">conceptual grounding pattern projected to *V1/*M1L</li>
      <li style="text-align: left;margin-left:10%;">category-critical wordform grounding pattern projected to *A1/*M1i</li>
      <li style="text-align: left;margin-left:10%;">instance-specific wordform grounding pattern projected to *A1/*M1i.</li>
    </ol>
    <p style="text-align: left;">All 60 instances activated grounding patterns of type (i), but only training instances activated grounding patterns of type (ii) and (iii). In total, a training instance is grounded by a quadruple including two conceptual and two wordform grounding patterns (projected to four primary areas), and a test instance is grounded by two conceptual grounding patterns (projected to two sensorimotor areas).</p>
    <p class="aligncenter" style="padding: 20px 0em 20px 0;"><img src="groundingpattern.png" width="900" alt="centered image"></p>
    
    <p style="text-align: left;">Out of 625 potential cells per area, a subset of twelve cells defined a grounding pattern: a conceptual grounding patterns (i) consisted of six unique neurons and six shared neurons (Figure 4, top row). Unique neurons served as representations of the idiosyncratic (instance-specific) visuomotor features; each feature only characterized one instance. This also applied for within-category instances to account for the fact that category exemplars are similar (but not identical) category instantiations. Shared neurons represented essential features to define a category; these features were available in all category members. Shared neurons served as the neuronal correlates between within-category instances and distinguished them from members of other categories. In sum, each category possessed 36 unique neurons from its six exemplars and six shared neurons (Figure 4, top row). Category-critical wordform grounding patterns (ii) represented category label and instance-specific wordform grounding patterns (iii) represented proper names of instances. The use of one label for all category members required the patterns (ii) of every three within-category training instances to possess the same twelve neurons (Figure 4, middle row). Because a proper name was distinct to an instance, each pattern of type (iii) comprised twelve idiosyncratic neurons; the result was 30 distinct wordform grounding patterns in total (Figure 2C, bottom row). The choice of cells for pattern generation was pseudorandomized and constrained by the following criteria: </p>
    <li style="text-align: left;margin-left:10%;">Within-category neurons had to be non-adjacent to each other. This prevented coactivation merely due to close distance.</li>
    <li style="text-align: left;margin-left:10%;">Neurons were activated in a category-specific manner, that is, no two categories shared any same neuron.</li>
    <li style="text-align: left;margin-left:10%;">For each instance, the grounding patterns in *V1 and *M1L, as wells as *A1 and *M1i, followed the same principles but were not necessarily identical.</li>
    <p class="aligncenter" style="padding: 20px 0em 20px 0;"><img src="DesignPattern.png" width="900" alt="centered image"></p>
    <p style="text-align: center;"><strong>Figure 4.</strong> Configuration of grounding patterns used in my simulation. The exemplary instances of the two categories a and b and their labels in italic grey words are provided for conceptual understanding of the experimental procedure. </p>
    
    
    
    
    
    
    
    
    </font>
    </body>
    </html>
